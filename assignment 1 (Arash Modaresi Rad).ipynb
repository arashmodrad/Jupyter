{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 533 Assignment 1: College Scorecard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**by Arash Modaresi Rad**\n",
    "\n",
    "## Project Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the most recent cohort’s data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to CollegeScorecardDataDictionary.xlsx the most recent cohort's data file is MERGED2017_18_PP.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'MERGED2017_18_PP.csv' does not exist: b'MERGED2017_18_PP.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-39ba73bd7d81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlatest_cohort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MERGED2017_18_PP.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'MERGED2017_18_PP.csv' does not exist: b'MERGED2017_18_PP.csv'"
     ]
    }
   ],
   "source": [
    "latest_cohort = pd.read_csv('MERGED2017_18_PP.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Describe the data set’s basic characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_cohort.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2017-18 data from college scorecards show that there are 7115 rows, and 1977 columns.\n",
    "Also this dataset contains 1894 float64, 14 int64, and 69 object typs of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_cohort.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. How many schools are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All schools are identified with a unique identification number namely `UNITID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of schools with unique location: ', latest_cohort['UNITID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equall to the number of rows of the dataset which means all of the elements are unique schools with separate locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we consider that several locations of an institution is considered one institution then `OPEID6` must be used to count the number of schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of schools considering several locations of an institution exists: ', latest_cohort['OPEID6'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. How many main and branch schools are there? (the variable MAIN is 1 for a main campus, and 0 for a branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of main schools: ', Counter(latest_cohort['MAIN']).get(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of btanch schools: ', Counter(latest_cohort['MAIN']).get(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. How many schools are there per state?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumeing that school branches are considered as seperate schools we can count the number of elements in each state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllSchools = Counter(latest_cohort['STABBR'])\n",
    "Num_allSchools = pd.DataFrame(AllSchools, index = [0])\n",
    "print('Number of all schools including the branches per state: ')\n",
    "Num_allSchools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumeing that school branches are considered as one school we can count the number of elements in each state by removing the duplicated values in `OPEID6` and counting the numbers per state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list1 = pd.DataFrame(latest_cohort);\n",
    "droped_list = new_list1.drop_duplicates(subset = ['OPEID6'], keep = 'first')\n",
    "## just for visual confirmation\n",
    "#bbb = bb.sort_values('OPEID6', ascending = True) \n",
    "Num_schools2 = pd.DataFrame(Counter(droped_list['STABBR']), index = [0])\n",
    "print('Number of all schools excluding the branches per state:')\n",
    "Num_schools2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. How are schools-per-state distributed? Describe this both numerically and with a plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the bar graphs of number of schools per state with two scenarios of \n",
    "\n",
    "considering school branches as seperate schools (`excluding branches`) and \n",
    "\n",
    "not considering school branches as seperate schools (`excluding branches`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = list(Num_allSchools.columns)\n",
    "ax1 = np.transpose(ax)\n",
    "#print(ax1)\n",
    "ax2 = Num_schools2.values[0]\n",
    "ax3 = Num_allSchools.values[0]\n",
    "#print(ax2)\n",
    "#print(np.arange(len(ax2)))\n",
    "plt.bar(np.arange(len(ax2)), ax2, align = 'center', alpha = 1)\n",
    "plt.bar(np.arange(len(ax3)), ax3, align = 'center', alpha = 0.5)\n",
    "plt.legend(['Excluding branches', 'Including branches'], loc = 1)\n",
    "plt.xticks(np.arange(len(ax2)), ax1, rotation = 'vertical')\n",
    "plt.tick_params(labelsize = 5)\n",
    "plt.ylabel('Number of schools')\n",
    "plt.xlabel('States')\n",
    "plt.title('Plot bar of schools per state')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lists to dictionary \n",
    "res = {'excluding branches': [], 'Including branches': []}\n",
    "range_list = np.arange(len(ax2))\n",
    "for i in range_list:\n",
    "    res['excluding branches'].append(ax2[i]) \n",
    "    res['Including branches'].append(ax3[i])  \n",
    "\n",
    "# calculate stats\n",
    "stat1 = pd.DataFrame(res['excluding branches']).describe()\n",
    "stat2 = pd.DataFrame(res['Including branches']).describe()\n",
    "print('ststistical properties of schools-per-state (excluding branches case): \\n', stat1)\n",
    "print('\\nststistical properties of schools-per-state (Including branches case): \\n', stat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident that in both cases the median is lower than the mean indicating positive skewness and in both cases the **median** is more appropriate to represent central tendency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ax2, density = True, bins = 10) \n",
    "plt.hist(ax3, density = True, bins = 10, alpha = 0.5) \n",
    "plt.legend(['Excluding branches', 'Including branches'], loc = 1)\n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('Value');\n",
    "plt.title('Histogram of number of schools per state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Examine numeric statistics - what are their averages? Think about what average is most appropriate! How are they distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. School enrollment (size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enrollment of all undergraduate students is a varaible named `UGDS` and it is an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "School_enrollment = latest_cohort['UGDS']\n",
    "stat_School_enrollment = pd.DataFrame(School_enrollment).describe()\n",
    "print(stat_School_enrollment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(School_enrollment, density = True, bins = 30) \n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('Value');\n",
    "plt.title('Histogram of number of schools enrollment')\n",
    "thirdQ = latest_cohort['UGDS'].describe().get('75%').astype('float64')\n",
    "firstQ  = latest_cohort['UGDS'].describe().get('25%').astype('float64')\n",
    "print('Inter-quartile range: ', np.subtract(thirdQ, firstQ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident that our data exhibits a positive skewness and therefore median is more appropriate to represent central tendency.\n",
    "Also both standrad deviation and the inter-quartile range are large (5481 and 1912, respectively) indicating large variablility between diferent schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now considering that **all school branches are considered as one school** we have to first groupby `OPEID6` and then sum their values so that all branches represent one school and then calculate the stats of school enrollment size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = latest_cohort.groupby(['OPEID6'], as_index = False).sum()\n",
    "stat_School_enrollment2 = df2['UGDS'].describe()\n",
    "print(stat_School_enrollment2)\n",
    "#print(stat_School_enrollment2.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histogram of school enrollment as **values of enrollment in all branches of the same school are sumed and represented as one school**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df2['UGDS'], density = True, bins = 30) \n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('Value');\n",
    "plt.title('Histogram of number of school enrollments')\n",
    "thirdQ = stat_School_enrollment2.iloc[6].astype('float64')\n",
    "firstQ  = stat_School_enrollment2.iloc[4].astype('float64')\n",
    "print('Inter-quartile range: ', np.subtract(thirdQ, firstQ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the data exhibits a positive skewness and therefore median is more appropriate to represent central tendency.\n",
    "Also both standrad deviation and the inter-quartile range are large (6145 and 2480, respectively) indicating large variablility between diferent schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Completion rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Admission rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the admission rate of diffrent schools, the two varaibles of `ADM_RATE` and `ADM_RATE_ALL` will be used, where the first is admission rate of all schools and the seccond merges the school branches and represents the overall admission rate of the school by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Admission = latest_cohort['ADM_RATE']\n",
    "stat_Admission = pd.DataFrame(Admission).describe()\n",
    "print(stat_Admission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Admission_All = latest_cohort['ADM_RATE_ALL']\n",
    "stat_Admission_All = pd.DataFrame(Admission_All).describe()\n",
    "print(stat_Admission_All)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histogram of admission rare as **both total admission rate and local schools admission rates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Admission, density = True, bins = 30) \n",
    "plt.hist(Admission_All, density = True, bins = 30, alpha = 0.7) \n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Value')\n",
    "plt.title('Histogram of admission rate')\n",
    "plt.legend(['Local admission rate', 'Total admission rate'], loc = 2)\n",
    "thirdQ = stat_Admission.iloc[6].astype('float64')\n",
    "firstQ  = stat_Admission.iloc[4].astype('float64')\n",
    "thirdQ_All = stat_Admission_All.iloc[6].astype('float64')\n",
    "firstQ_All = stat_Admission_All.iloc[4].astype('float64')\n",
    "print('Admission rate Inter-quartile range: ', np.subtract(thirdQ, firstQ))\n",
    "print('Total dmission rate Inter-quartile range: ', np.subtract(thirdQ_All, firstQ_All))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The admission data exhibits a negative skewness and the diffrence between mean and median is both cases is insignifcant and therefore, both are appropriate for representing centarl tendency of data.\n",
    "Also both standrad deviation and the inter-quartile range are not very large (~0.2 and ~0.3, respectively) indicating medium variablility between diferent schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Tuition & fees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Cost (Average Cost of Attendance, COSTT4_A/COSTT4_P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis the `COSTT4_A` data are used that represent the average annual total cost of attendance, including tuition and fees, books and supplies, and living expenses for all full-time, first-time, degree/certificate-seeking undergraduates who receive Title IV aid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cost = latest_cohort['COSTT4_A']\n",
    "stat_Cost = pd.DataFrame(Cost).describe()\n",
    "print(stat_Cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histogram of average cost of attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Cost, density = True, bins = 30) \n",
    "plt.ylabel('Frequency');\n",
    "plt.xlabel('Value');\n",
    "plt.title('Histogram of cost of attendance')\n",
    "thirdQ = stat_Cost.iloc[6].astype('float64')\n",
    "firstQ  = stat_Cost.iloc[4].astype('float64')\n",
    "print('Inter-quartile range: ', np.subtract(thirdQ, firstQ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost of attendance data exhibits a positive skewness and the diffrence between mean and median is both cases is signifcant fue to presence of few number of large data in our dataset and therefore, median is appropriate for representing centarl tendency of data.\n",
    "Also both standrad deviation and the inter-quartile range are very large (15015 and 19941, respectively)indicating high variablility between diferent schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Break down completion rate by school characteristics (box plots are useful for this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
